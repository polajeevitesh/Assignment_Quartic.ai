{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing PySpark Packages\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import StructType, StringType\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Assignment\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Schema of the Stream Tables\n",
    "#Included 4 new columns apart from initial columns timestamp, t1, t3, t3 tags\n",
    "#t3_modified to convert the stringformat of t3 to boolean value\n",
    "#t1_counter, t2_counter, t3_counter to keep track of consecutive occurences\n",
    "userSchema = StructType().add(\"timestamp\", \"string\").add(\"t1\", \"double\").add(\"t2\", \"integer\").add(\"t3\", \"string\").add(\"t3_modified\",\"boolean\").add(\"t1_counter\", \"integer\").add(\"t2_counter\", \"integer\").add(\"t3_counter\", \"integer\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the input stream from the csv from the local Directory\n",
    "#If we are reading JSON data we need to use json conversion statement\n",
    "csvDF = spark.readStream.option(\"sep\", \",\").schema(userSchema).csv(\"C:/Users/polaramesh/Desktop/Assignment\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the Global counters to keep track of the consecutive occurences\n",
    "t1_counter_value = 0\n",
    "t2_counter_value = 0\n",
    "t3_counter_value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert the t3 counter to boolean value\n",
    "def update_t3_modified(t3):\n",
    "    if(t3 == \"ON\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to track 4 consecutive occurences for tag t1 @ t1>55.43 \n",
    "def t1_counter(t1):\n",
    "    global t1_counter_value\n",
    "    if(t1 > 55.43):\n",
    "        if(t1_counter_value == 4):\n",
    "            t1_counter_value = 0\n",
    "            t1_counter_value = t1_counter_value + 1\n",
    "            return t1_counter_value\n",
    "        else:\n",
    "            t1_counter_value = t1_counter_value + 1\n",
    "            return t1_counter_value\n",
    "    else:\n",
    "        t1_counter_value = 0\n",
    "        return t1_counter_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to track 6 consecutive occurences for tag t2 @ t2<20\n",
    "def t2_counter(t2):\n",
    "    global t2_counter_value\n",
    "    if(t2 < 20):\n",
    "        if(t2_counter_value == 6):\n",
    "            t2_counter_value = 0\n",
    "            t2_counter_value = t2_counter_value + 1\n",
    "            return t2_counter_value\n",
    "        else:\n",
    "            t2_counter_value = t2_counter_value + 1\n",
    "            return t2_counter_value\n",
    "    else:\n",
    "        t2_counter_value = 0\n",
    "        return t2_counter_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to track 3 consecutive occurences for tag t3 @ t3==ON\n",
    "def t3_counter(t3):\n",
    "    global t3_counter_value\n",
    "    if(t3 == 1):\n",
    "        if(t3_counter_value == 3):\n",
    "            t3_counter_value = 0\n",
    "            t3_counter_value = t3_counter_value + 1\n",
    "            return t3_counter_value\n",
    "        else:\n",
    "            t3_counter_value = t3_counter_value + 1\n",
    "            return t3_counter_value\n",
    "    else:\n",
    "        t3_counter_value = 0\n",
    "        return t3_counter_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating UDF's\n",
    "fun1 = udf(update_t3_modified)\n",
    "fun2 = udf(t1_counter)\n",
    "fun3 = udf(t2_counter)\n",
    "fun4 = udf(t3_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifying the initial null entries for tracking tags with actual occurences\n",
    "csvDF=csvDF.withColumn(\"t3_modified\", fun1(csvDF['t3']))\n",
    "csvDF=csvDF.withColumn(\"t1_counter\", fun2(csvDF['t1']))\n",
    "csvDF=csvDF.withColumn(\"t2_counter\", fun3(csvDF['t2']))\n",
    "csvDF=csvDF.withColumn(\"t3_counter\", fun4(csvDF['t3_modified']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new dataframe to select 4th consecutive rule break for tag t1\n",
    "rule_id_1 = csvDF.select('timestamp').where('t1_counter == 4')\n",
    "rule_id_1 = rule_id_1.withColumn(\"rule_id\",lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new dataframe to select 6th consecutive rule break for tag t2\n",
    "rule_id_2 = csvDF.select('timestamp').where('t2_counter == 6')\n",
    "rule_id_2 = rule_id_2.withColumn(\"rule_id\",lit(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new dataframe to select 3rd consecutive rule break for tag t3\n",
    "rule_id_3 = csvDF.select('timestamp').where('t3_counter == 3')\n",
    "rule_id_3 = rule_id_3.withColumn(\"rule_id\",lit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new dataframe to union all the above dataframes with corresponding timestamp and Rule_id's\n",
    "RULE_BREAK = rule_id_1.union(rule_id_2).union(rule_id_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the RULE_BREAK dataframe on to the console\n",
    "#as mentioned the interval time is set to 1 minute, can be increased on decreased inside the trigger function\n",
    "#If we want to store the result into some table at HDFS/S3 location the details need to be specified at option('path', '/path/to/destination/directory')\n",
    "#Storage format can be mentioned at format('parquet') - for parquet file format\n",
    "query = RULE_BREAK.writeStream.format('console').option('truncate', 'False').trigger(processingTime='60 seconds').start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
